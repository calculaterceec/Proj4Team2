{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f072a0-0fec-4210-b79a-a930641adbf5",
   "metadata": {},
   "source": [
    "# Reading and Cleaning Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78246110-48e1-45ac-87dc-aa6a50ca5cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3050558f-1e58-4957-a777-837a6ba56383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdc wonder Daily Air Temp by County (aggregated by month)\n",
    "# Jan 1, 1979 - Dec 31, 2011\n",
    "#temp_df = pd.read_csv('data/climate_data/2011_AirTemp_byState.txt', delimiter=\"\\t\", header=0)\n",
    "#particulateMatter_df = pd.read_csv('data/climate_data/2011_fineParticulateMatter_Âµgm3.txt', delimiter=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8374b7c-6249-4d4f-90be-048d96bf3024",
   "metadata": {},
   "source": [
    "# Read in Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1859e2b8-953f-49c8-bacc-581d6876632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_files = os.listdir('../data/01_climate_data/monthlyAirTemp_byCounty_RAW/')\n",
    "temperature_files.remove('.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c49c73f-0aae-4dbf-ab8f-5b95189cc2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the above easier with a function to grab data in folder, read it in, remove unwanted stuff and return a clean df\n",
    "def process_temp_data(filename):\n",
    "    file_string = '../data/01_climate_data/monthlyAirTemp_byCounty_RAW/' + filename\n",
    "    temp_df = pd.read_csv(file_string, delimiter='\\t', header=0, parse_dates=['Month, Year Code'], dtype={'County Code': object})\n",
    "    \n",
    "    #drop unneccesary rows\n",
    "    temp_df = temp_df[temp_df['County'].isna() == False]\n",
    "    temp_df = temp_df[temp_df['Notes'] != 'Total'] #drop the total rows\n",
    "    \n",
    "    # create UID\n",
    "    temp_df['UID'] = temp_df['County'] + \" - \" + temp_df['Month, Year']\n",
    "    \n",
    "    #get only needed columns\n",
    "    output_df = temp_df[['UID', 'County', 'County Code', 'Month, Year', 'Month, Year Code','Avg Daily Max Air Temperature (F)', 'Min Temp for Daily Max Air Temp (F)', 'Max Temp for Daily Max Air Temp (F)']]\n",
    "    output_df = output_df.rename(columns={'Avg Daily Max Air Temperature (F)': 'avg_dailyMaxAirTemp_F', 'Min Temp for Daily Max Air Temp (F)': 'min_dailyMaxAirTemp_F', 'Max Temp for Daily Max Air Temp (F)': 'max_dailyMaxAirTemp_F'})\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a93a35f-49a9-4b18-a924-f5d33ba1c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run process data function on all data in temperature files\n",
    "air_temperature_df = [process_temp_data(file) for file in temperature_files]\n",
    "air_temperature_df = pd.concat(air_temperature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935a4444-23ca-447b-b78f-c9e888346ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn objects to categories to save memory\n",
    "air_temperature_df['County'] = air_temperature_df['County'].astype('category')\n",
    "air_temperature_df['Month, Year'] = air_temperature_df['Month, Year'].astype('category')\n",
    "air_temperature_df['Month, Year Code'] = air_temperature_df['Month, Year Code'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21297e-57af-476c-adad-1df83354d52d",
   "metadata": {},
   "source": [
    "# Read in Precipitation Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a43a34c-4602-40aa-8214-4d4b9a05d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_files = os.listdir('../data/01_climate_data/monthlyPrecipitation_RAW/')\n",
    "#precipitation_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae7c657e-6c8a-46a4-bed5-7ae361053b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing a function to process precip data\n",
    "def process_precip(filename):\n",
    "    file_string = '../data/01_climate_data/monthlyPrecipitation_RAW/' + filename\n",
    "    precip_df = pd.read_csv(file_string, delimiter='\\t', header=0, dtype={'County Code': object}, parse_dates=['Month, Year Code'])\n",
    "    \n",
    "    #drop unneccesary rows\n",
    "    precip_df = precip_df[precip_df['County'].isna() == False]\n",
    "    precip_df = precip_df[precip_df['Notes'] != 'Total'] #drop the total rows\n",
    "    \n",
    "    #county code to int\n",
    "    #precip_df = precip_df.astype({'County Code': 'int64'})\n",
    "    \n",
    "    # create UID\n",
    "    precip_df['UID'] = precip_df['County'] + \" - \" + precip_df['Month, Year']\n",
    "    \n",
    "    #get only needed columns\n",
    "    output_df = precip_df[['UID', 'County', 'County Code', 'Month, Year', 'Month, Year Code', 'Avg Daily Precipitation (mm)' ,'Min Daily Precipitation', 'Max Daily Precipitation']]\n",
    "    final_df = output_df.rename(columns={'Avg Daily Precipitation (mm)': 'avg_daily_precip_mm', 'Min Daily Precipitation': 'min_daily_precip_mm', 'Max Daily Precipitation': 'max_daily_precip_mm'})\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9b9058-a2b0-4508-b3d9-ad098b26d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_df = [process_precip(file) for file in precipitation_files]\n",
    "precipitation_df = pd.concat(precipitation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66bfeac5-456f-4c45-9ec4-59f51c1d9e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn objects to categories to save memory\n",
    "precipitation_df['County'] = precipitation_df['County'].astype('category')\n",
    "precipitation_df['Month, Year'] = precipitation_df['Month, Year'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c4830-cdb6-484e-8be1-46c24164e11f",
   "metadata": {},
   "source": [
    "# Combining Air Temp and Precip Climate Dfs into One\n",
    "\n",
    "Here we will combine all climate data into one master data frame (sans the heat wave data, since that is not monthly), and write out to a zipped csv. This is to save on file size for github file size limits.\n",
    "\n",
    "\n",
    "Ultimately, we ended up not using this data, but for the sake of showing functions one might use to read in and combine such data, I've included the workflow in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4fd74fa-65aa-4dcd-b6df-6305ae65b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_airTemp = pd.merge(air_temperature_df, precipitation_df, left_on='UID', right_on='UID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f95c2f2-70f6-41eb-ba59-fc70e8bd0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_airTemp.drop(columns=['UID','County_y', 'County Code_y', 'Month, Year_y', 'Month, Year Code_y'], inplace=True)\n",
    "\n",
    "#renaming for later\n",
    "precip_airTemp.rename(columns={'County_x': 'county_name', 'County Code_x': 'county_FIPS', 'Month, Year_x': 'month_year_long', 'Month, Year Code_x': 'month_year_short'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10eb0ca1-9cf3-41dc-80cd-403167c73e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn objects to categories to save memory\n",
    "precip_airTemp['county_name'] = precip_airTemp['county_name'].astype('category')\n",
    "precip_airTemp['county_FIPS'] = precip_airTemp['county_FIPS'].astype('category')\n",
    "precip_airTemp['month_year_long'] = precip_airTemp['month_year_long'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "752d6137-a5c0-4787-85cf-656979bf5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing out to a zipped csv for later use\n",
    "final_compression_opts = dict(method='zip',\n",
    "                        archive_name='precip_AirTemp_monthly_1979_2011.csv')\n",
    "\n",
    "precip_airTemp.to_csv('../data/cleaned/precip_AirTemp_monthly_1979_2011.zip', compression=final_compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa91b3-9673-46f9-b6ec-28e31ec485c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d715ede4-f6d5-4789-84e6-ea95411ec2d3",
   "metadata": {},
   "source": [
    "# Read in the Heat Wave Days\n",
    "Again, this was part of the climate data we didn't really use. \n",
    "\n",
    "Included to show process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7059b95e-41f5-4bc4-b067-104f73882e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_files = os.listdir('../data/01_climate_data/heatWaveDays_RAW/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bac87f4-ec0c-4765-ac73-0c07a5416320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_heat_wave_data(filename):\n",
    "    file_string = '../data/01_climate_data/heatWaveDays_RAW/' + filename\n",
    "    hw_df = pd.read_csv(file_string, delimiter='\\t', header=0, parse_dates=['Year'], dtype={'County Code': object})\n",
    "    \n",
    "    #drop unneccesary rows\n",
    "    hw_df = hw_df[hw_df['County'].isna() == False]\n",
    "    hw_df = hw_df[hw_df['Notes'] != 'Total'] #drop the total rows\n",
    "    \n",
    "    #county code to int\n",
    "    #hw_df = hw_df.astype({'County Code': 'int64'})\n",
    "    \n",
    "    # No UID in this df, since it doesn't have the Month, Year col\n",
    "\n",
    "    \n",
    "    #get only needed columns\n",
    "    output_df = hw_df[['County', 'County Code', 'Year', 'Heat Wave Days Based on Daily Maximum Temperature', 'Heat Wave Days Based on Daily Maximum Heat Index', 'Heat Wave Days Based on Net Daily Heat Stress']]\n",
    "    final_df = output_df.rename(columns={'Heat Wave Days Based on Daily Maximum Temperature': 'count_hwDays_onDailyMaxTemp', 'Heat Wave Days Based on Daily Maximum Heat Index': 'count_hwDays_onDailyMaxHeatIndex', 'Heat Wave Days Based on Net Daily Heat Stress': 'count_hwDays_onDailyNetHeatStress'})\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f169167-f97c-451d-8cf1-d57ced9c4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_wave_df = [process_heat_wave_data(file) for file in heat_files]\n",
    "heat_wave_df = pd.concat(heat_wave_df)\n",
    "heat_wave_df.sort_values(by=['County Code', 'Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e3bba5-48d5-4f48-8bd7-3c5b1d1bfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heat_wave_df.memory_usage(deep=True) / 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "331bb0cc-a350-475b-8c34-7cbc5302c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_wave_df.to_csv('../data/cleaned/heat_wave_days_1981_2010.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a2d5c-ddb4-4c64-a9cd-bfd5977a6807",
   "metadata": {},
   "source": [
    "# Inspecting Health Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b27a41f-60d1-4057-b6ff-bc398621a8e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cancer_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-774e80a701b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minf_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.ipynb_checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msubstance_injury_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.ipynb_checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcancer_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.ipynb_checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cancer_files' is not defined"
     ]
    }
   ],
   "source": [
    "cvd_files = os.listdir('../data/03_health_data/IHME_USA_COUNTY_CVD_MORTALITY_RATES_1980_2014/')\n",
    "inf_files = os.listdir('../data/03_health_data/IHME_USA_COUNTY_INFECT_DIS_MORT_1980_2014/')\n",
    "resp_files = os.listdir('../data/03_health_data/IHME_USA_COUNTY_RESP_DISEASE_MORTALITY_1980_2014/')\n",
    "substance_injury_files = os.listdir('../data/03_health_data/IHME_USA_COUNTY_USE_INJ_MORTALITY_1980_2014/')\n",
    "\n",
    "cvd_files.remove('.ipynb_checkpoints')\n",
    "inf_files.remove('.ipynb_checkpoints')\n",
    "substance_injury_files.remove('.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "363ef29b-73aa-49a8-b4a3-80c2fef96972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal function to process data in all folders\n",
    "def process_health_data(file):\n",
    "    state = file.split('_')[-2].title()\n",
    "    stat_type = file.split('_')[3]\n",
    "    \n",
    "    #set filepath based on stat_type\n",
    "    if stat_type == 'CVD':\n",
    "        folder = '../data/03_health_data/IHME_USA_COUNTY_CVD_MORTALITY_RATES_1980_2014/'\n",
    "    elif stat_type == 'INFECT':\n",
    "        folder = '../data/03_health_data/IHME_USA_COUNTY_INFECT_DIS_MORT_1980_2014/'\n",
    "    elif stat_type == 'RESP':\n",
    "        folder = '../data/03_health_data/IHME_USA_COUNTY_RESP_DISEASE_MORTALITY_1980_2014/'\n",
    "    elif stat_type == 'CANCER':\n",
    "        folder = '../data/03_health_data/IHME_USA_COUNTY_CANCER_MORTALITY_RATES_1980_2014/'\n",
    "    elif stat_type == 'USE':\n",
    "        folder = '../data/03_health_data/IHME_USA_COUNTY_USE_INJ_MORTALITY_1980_2014/'\n",
    "    full_path = folder + file\n",
    "    #print(full_path)\n",
    "    \n",
    "    #read in csv\n",
    "    df = pd.read_csv(full_path, dtype={'FIPS': object})\n",
    "    # drop rows that are sums of whole state\n",
    "    df = df[(df['location_name'] != state) & (df['FIPS'].isna() == False)]\n",
    "    \n",
    "    #recase cols to save memory and so we can create a UID later\n",
    "    # UID is formatted: 'FIPS-cause_id-sex_id-year_id'\n",
    "    #df[['cause_id', 'sex', 'cause_name', 'location_name', 'FIPS']] = df[['location_name', 'FIPS', 'cause_id', 'sex', 'cause_name']].astype('category')\n",
    "    #df['UID'] = df['FIPS'] + '-' + df['cause_id'] + '-' + df['sex_id'] + '-' + df['year_id']\n",
    "    df['state'] = state\n",
    "    df.drop(columns=['sex_id', 'location_id'], inplace=True)\n",
    "    \n",
    "    #recast variables as category for file size handling\n",
    "    #df[['location_name', 'FIPS', 'cause_id', 'cause_name', 'sex_id', 'sex', 'year_id', 'UID']] = df[['location_name', 'FIPS', 'cause_id', 'cause_name', 'sex_id', 'sex', 'year_id', 'UID']].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2def429-3fc5-4977-b94b-47b28da2ca7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# process cardiovascular mortality data\n",
    "full_cvd_df = [process_health_data(file) for file in cvd_files]\n",
    "full_cvd_df = pd.concat(full_cvd_df)\n",
    "\n",
    "full_cvd_df['FIPS'] = full_cvd_df['FIPS'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d231e8e-68a0-4270-90b3-764f98392c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process infectious disease mortality data\n",
    "full_inf_df = [process_health_data(file) for file in inf_files]\n",
    "full_inf_df = pd.concat(full_inf_df)\n",
    "\n",
    "full_inf_df['FIPS'] = full_inf_df['FIPS'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1424be8d-03f6-42fb-835d-558211de2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process respiratory disease mortality data\n",
    "full_resp_df = [process_health_data(file) for file in resp_files]\n",
    "full_resp_df = pd.concat(full_resp_df)\n",
    "\n",
    "full_resp_df['FIPS'] = full_resp_df['FIPS'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e29ecc00-4ba4-4a30-b00d-422082e74034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process substance abuse/self injury disease mortality data\n",
    "full_subInj_df = [process_health_data(file) for file in substance_injury_files]\n",
    "full_subInj_df = pd.concat(full_subInj_df)\n",
    "\n",
    "full_subInj_df['FIPS'] = full_subInj_df['FIPS'].str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6fb6684-244a-4df0-a979-27508ce23b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all the unnecessary columns\n",
    "full_cvd_df.drop(columns=['measure_id', 'measure_name', 'cause_id', 'age_id', 'age_name', 'metric', 'upper', 'lower'], inplace=True)\n",
    "full_inf_df.drop(columns=['measure_id', 'measure_name', 'cause_id', 'age_id', 'age_name', 'metric', 'upper', 'lower'], inplace=True)\n",
    "full_resp_df.drop(columns=['measure_id', 'measure_name', 'cause_id', 'age_id', 'age_name', 'metric', 'upper', 'lower'], inplace=True)\n",
    "full_subInj_df.drop(columns=['measure_id', 'measure_name', 'cause_id', 'age_id', 'age_name', 'metric', 'upper', 'lower', 'measure_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5a637e4-b41a-467f-9ce8-9f94d5188c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cvd_df[['location_name', 'FIPS', 'cause_name', 'sex', 'year_id', 'state']] = full_cvd_df[['location_name', 'FIPS', 'cause_name', 'sex', 'year_id', 'state']].astype('category')\n",
    "\n",
    "full_inf_df[['location_name', 'FIPS', 'cause_name', 'sex', 'year_id', 'state']] = full_inf_df[['location_name', 'FIPS', 'cause_name', 'sex', 'year_id', 'state']].astype('category')\n",
    "\n",
    "full_resp_df[['location_name', 'FIPS', 'cause_name', 'sex', 'year_id', 'state']] = full_resp_df[['location_name', 'FIPS', 'cause_name', 'sex', 'year_id', 'state']].astype('category')\n",
    "\n",
    "full_subInj_df[['location_name', 'FIPS', 'cause_name', 'sex', 'year_id', 'state']] = full_subInj_df[['location_name', 'FIPS', 'cause_name', 'sex', 'year_id', 'state']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82786add-b4cb-437c-bd7b-f2a078d23002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a Unique Identifier to join later with other climate dfs\n",
    "cvd_df_compression_opts = dict(method='zip',\n",
    "                        archive_name='cvd_mortality.csv')\n",
    "\n",
    "full_cvd_df.to_csv('../data/cleaned/cvd_mortality.zip', index=False, compression=cvd_df_compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c384c26f-fa7e-43ed-9cba-cd42d2603ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a Unique Identifier to join later with other climate dfs\n",
    "inf_df_compression_opts = dict(method='zip',\n",
    "                        archive_name='inf_mortality.csv')\n",
    "\n",
    "full_inf_df.to_csv('../data/cleaned/inf_mortality.zip', index=False, compression=inf_df_compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09c984ac-637b-402e-8990-41556cf0cab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a Unique Identifier to join later with other climate dfs\n",
    "resp_df_compression_opts = dict(method='zip',\n",
    "                        archive_name='resp_mortality.csv')\n",
    "\n",
    "full_resp_df.to_csv('../data/cleaned/resp_mortality.zip', index=False, compression=resp_df_compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63ffddf0-b099-4967-bcd8-56e39d7865d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a Unique Identifier to join later with other climate dfs\n",
    "subInj_df_compression_opts = dict(method='zip',\n",
    "                        archive_name='substanceAbuse_selfInjury_mortality.csv')\n",
    "\n",
    "full_subInj_df.to_csv('../data/cleaned/substanceAbuse_selfInjury_mortality.zip', index=False, compression=subInj_df_compression_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d8b711-7227-4422-af67-c4812925e1cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Creating Texas Only Data for Streamlit App\n",
    "\n",
    "For the purposes of building our interactive data visualization application, we choose to implement a web app using streamlit. Because we had not yet covered databases, we opted to load and visualize a smaller dataset -- \n",
    "\n",
    "This is our ***\"Texas Case Study\"*** where we visualize climate, health and demographic data, as well as our K-Means Clustering. \n",
    "\n",
    "But First, I'm going to go ahead and create some Texas Data to improve our applications rendering time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dd48aa8-0755-49d2-9cbe-32aeffed5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all of the Texas Health Data\n",
    "tx_cvd_df = full_cvd_df[full_cvd_df['state'] == 'Texas']\n",
    "tx_inf_df = full_inf_df[full_inf_df['state'] == 'Texas']\n",
    "tx_resp_df = full_resp_df[full_resp_df['state'] == 'Texas']\n",
    "tx_subInj_df = full_subInj_df[full_subInj_df['state'] == 'Texas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0277f0ef-3e40-4817-bdc6-2784825187ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the texas climate data\n",
    "precip_airTemp['county_name'] = precip_airTemp['county_name'].astype(object)\n",
    "#precip_airTemp\n",
    "\n",
    "climate_df = pd.read_csv('../data/cleaned/precip_AirTemp_monthly_1979_2011.zip', parse_dates=['month_year_long'], dtype={'county_FIPS': object, 'county_name': object})\n",
    "#climate_df\n",
    "\n",
    "#climate_df['county_name'].str.split(', ')[1000][1]\n",
    "\n",
    "climate_df['state'] = [i.split(', ')[1] for i in climate_df['county_name']]\n",
    "\n",
    "climate_df.drop(columns=['Unnamed: 0', 'month_year_short'], inplace=True)\n",
    "\n",
    "tx_climate_df = climate_df[climate_df['state'] == 'TX']\n",
    "\n",
    "heat_wave_df['state'] = [i.split(', ')[1] for i in heat_wave_df['County']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52fac696-03e8-4167-97b9-e2691d097ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_heat_wave_df = heat_wave_df[heat_wave_df['state'] == 'TX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9d339a5-09fe-4c3b-8117-ac3f3629915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tx demographics file\n",
    "demographics_df = pd.read_csv('../data/cleaned/final_combined.csv', dtype={'fips': object})\n",
    "tx_demographics = demographics_df[demographics_df['state'] == ' Texas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce66082d-42be-4712-98be-2d57bc51820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out all TX data frames & stuff to CSV\n",
    "\n",
    "# tx_subInj_df, tx_cvd_df, tx_inf_df, tx_resp_df\n",
    "tx_cvd_df.to_csv('../data/cleaned/tx_for_streamlit/tx_cvd.csv', index=False)\n",
    "tx_inf_df.to_csv('../data/cleaned/tx_for_streamlit/tx_inf.csv', index=False)\n",
    "tx_resp_df.to_csv('../data/cleaned/tx_for_streamlit/tx_resp.csv', index=False)\n",
    "tx_subInj_df.to_csv('../data/cleaned/tx_for_streamlit/tx_subInj.csv', index=False)\n",
    "\n",
    "# tx_demographics, tx_heat_wave_df, tx_climate_df\n",
    "tx_demographics.to_csv('../data/cleaned/tx_for_streamlit/tx_demographics.csv', index=False)\n",
    "tx_heat_wave_df.to_csv('../data/cleaned/tx_for_streamlit/tx_heat_wave.csv', index=False)\n",
    "tx_climate_df.to_csv('../data/cleaned/tx_for_streamlit/tx_climate_wave.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2318d-e99b-4a0f-a1b8-fa12439e014f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
